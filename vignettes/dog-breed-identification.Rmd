---
title: "Dog Breed Identification"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Dog Breed Identification}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(torch)
library(torchvision)
library(dogbreed)

device <- if(cuda_is_available()) "cuda" else "cpu"

DATASET_FOLDER <- "~/datasets/"
NUM_WORKERS <- 8
BATCH_SIZE <- 16
NUM_EPOCHS <- 20
```

## Dataset

```{r}
train_transform <- function(img) {
  img <- img %>%
    # first convert image to tensor
    torchvision::transform_to_tensor() %>%
    # data augmentation
    torchvision::transform_random_affine(15, shear = c(-10, 10)) %>%
    # data augmentation
    torchvision::transform_random_resized_crop(size = c(224, 224)) %>%
    # data augmentation
    torchvision::transform_color_jitter() %>%
    # data augmentation
    torchvision::transform_random_horizontal_flip() %>%
    # normalize according to what is expected by resnet
    torchvision::transform_normalize(
      mean = c(0.485, 0.456, 0.406),
      std = c(0.229, 0.224, 0.225)
    ) 
  img[..,1:224,1:224]
}

submission_transform <- function(img) {
  img <- img %>%
    torchvision::transform_to_tensor() %>%
    torchvision::transform_resize(size = c(224, 224)) %>%
    torchvision::transform_normalize(
      mean = c(0.485, 0.456, 0.406), 
      std = c(0.229, 0.224, 0.225)
    )
  img[..,1:224,1:224]
}

train <- dog_breed_dataset(
  root = DATASET_FOLDER, 
  download = TRUE,
  force = FALSE,
  split = "train", 
  loader = magick_loader, 
  transform = train_transform
)

submission <- dog_breed_dataset(
  root = DATASET_FOLDER, 
  download = TRUE,
  force = FALSE,
  split = "submission", 
  loader = base_loader, 
  transform = submission_transform
)
```

```{r}
train_dl <- dataloader(
  dataset = train, 
  batch_size = BATCH_SIZE, 
  shuffle = TRUE,
  num_workers = NUM_WORKERS,
  worker_globals = c("device")
)

submission_dl <- dataloader(
  dataset = submission, 
  batch_size = BATCH_SIZE, 
  shuffle = FALSE,
  num_workers = NUM_WORKERS,
  worker_globals = c("device")
)
```

## Model

```{r}
nn_dog <- nn_module(
  "DogNN",
  initialize = function(n_classes = 120) {
    resnet18 <- torchvision::model_resnet18(pretrained = TRUE)
    resnet18$parameters %>% purrr::walk(function(param) param$requires_grad_(FALSE))
    
    num_features <- resnet18$fc$in_features
    resnet18$fc <- torch::nn_linear(
      in_features = num_features, 
      out_features = n_classes
    )
    
    self$resnet18 <- resnet18
  },
  forward = function(x) {
    x %>%
      self$resnet18()
  }
)

model <- nn_dog()$to(device = device)
print(model)
```

## Training

```{r}
set_progress_bar <- function(total) {
  progress::progress_bar$new(
    total = total, clear = FALSE, width = 70,
    format = ":current/:total [:bar] - :elapsed - loss: :loss"
  )
}

n_epochs <- NUM_EPOCHS
loss_function <- nn_cross_entropy_loss()
optimizer <- optim_sgd(model$parameters, lr = 0.1, momentum = 0.9)
scheduler <- lr_one_cycle(optimizer, max_lr = 0.05, epochs = n_epochs, steps_per_epoch = train_dl$.length())
```

```{r}
for(epoch in 1:n_epochs) {
  # progress bar for feedback
  pb <- set_progress_bar(length(train_dl))
  pb$message(glue::glue("Epoch {epoch}/{n_epochs}"))
  
  model$train()
  losses <- c()
  
  coro::loop(for(b in train_dl) {
    
    optimizer$zero_grad()
    output <- model(b[[1]]$to(device = device))
    target <- b[[2]]$to(device = device)
    loss <- loss_function(output, target)
    loss$backward()
    optimizer$step()
    scheduler$step()
    
    losses <- c(losses, loss$item())
    pb$tick(tokens = list(loss = round(mean(losses), 4)))
  })
  
  model$eval()
}
```


